{% extends "main/layouts/base.html" %}
{% load static %}

{% block content %}
<div class="parallax-container">
    <div class="parallax"><img src="{% static 'main/images/robot-2.jpg' %}"></div>
    <div class="container">
        <div class="row"></div>
        <div class="row"></div>
        <div class="row"></div>
        <div class="row"></div>
        <div class="row"></div>
        <div class="row"></div>
        <div class="row"></div>
        <div class="row"></div>
        <div class="row"></div>
        <div class="row"></div>
        <div class="row"></div>
        <div class="row"></div>
        <div class="row"></div>
        <div class="row"></div>
        <div class="row"></div>
        <div class="row ">
            <div class="col s12 m3"></div>
            <div class="col s12 m1"></div>
            <div class="col s12 m6">
                <form id="form1" method="POST" action='/'>
                    {% csrf_token %}
                    <button class="btn-large waves-effect waves-light blue-grey darken-4" type="submit" id="btn1"
                        name="action" onClick={this.disabled}>Generate Music
                        <i class="material-icons right">library_music</i>
                    </button>
                </form>
            </div>
        </div>
    </div>
</div>
</div>


<div class="container blue-grey ">
    <div class="row">
        <div class="col l6 s12">
            <h5 class="grey-text text-lighten-4 font-serif">About the Model</h5>
            <p class="grey-text text-lighten-4 font-serif"> It is a Deep Learning Sequence Model
                which consists of many LSTM, Dense and Dropout layers. It predicts
                the notes and chords which shouldcome after a seuence of notes
                provided. The model consists over 5 million trained parameters.
                It is built on <a class="brown-text lighten-4 font-serif" href="http://keras.io">Keras</a>
                and <a class="brown-text darken-1 font-serif" href="http://tensorflow.org">Tensorflow</a>
                as backend.The website is built with 
                <a class="brown-text darken-1 font-serif" href="https://docs.djangoproject.com/en/3.0/">Django</a> 
                Framework used in backend, and 
                <a class="brown-text darken-1 font-serif" href="https://materializecss.com">MaterializeCSS</a>
                 in front end. To know more about the model visit my 
                <a class="brown-text darken-1 font-serif" href="https://github.com/gauravv0412/Music-Generation-using-Deep-Learning">
                    Github Repo</a>.
            </p>
        </div>
        <div class="col l6 s4">
            <img class="responsive-img" src="{% static 'main/images/keras.jpg' %}" alt="">
        </div>
    </div>
</div>
<div class="parallax-container">
    <div class="parallax"><img class="responsive-img" src="{% static 'main/images/robo-piano.jpg' %}"></div>
</div>

<div class="container blue-grey">
    <div class="row"></div>
    <div class="row">
        <div class="col l8 s12">
            <h5 class="grey-text text-lighten-4 font-serif">About Music Generation Project</h5>
            <p class="grey-text text-lighten-4 font-serif"> 
                In this project I trained my Deep Learning model on piano instrumental music which 
                were available in MIDI format. In this format we have details of notes(a keystroke), chords(combination
                of keys) and their offset(time when a key(s) is pressed). We use this information to train
                model to predict that given these combination of keys which should be the next key(s) to be pressed.
                The model has recognised 600 different chords and notes (on different octaves), and using
                them has produced great results.
            </p>
        </div>
        <div class="col l4 s4">
            <img class="responsive-img" src="{% static 'main/images/giphy11.gif' %}" alt="">
        </div>
    </div>
</div>

<div class="parallax-container">
    <div class="parallax"><img class="responsive-img" src="{% static 'main/images/chest-xray.jpg' %}"></div>
</div>

<div class="container blue-grey ">
    <div class="row"></div>
    <div class="row">
        <div class="col l9 s12">
            <h5 class="grey-text text-lighten-4 font-serif">About Dataset</h5>
            <p class="grey-text text-lighten-4 font-serif"> I used Maestro dataset for this project 
                from <a class = "brown-text lighten-4 font-serif" href="https://magenta.tensorflow.org/datasets/maestro#v200">https://magenta.tensorflow.org/datasets/maestro#v200</a>. MAESTRO (MIDI and Audio 
                Edited for Synchronous TRacks and Organization) is a dataset composed of over 200 
                hours of virtuosic piano performances captured with fine alignment (~3 ms) between 
                note labels and audio waveforms.
            </p>
        </div>
        <div class="col l3 s4">
            <img class="responsive-img" src="{% static 'main/images/xray1.jpg' %}" alt="">
        </div>
    </div>
</div>
{% endblock %}

{% block javascript %}
<script>
</script>

{% endblock %}